# MLPC-GROUP-ASSIGNMENT-

This project implements and compares serial and parallel versions of a Genetic Algorithm (GA) to optimize a problem using a dataset with 10 nodes, 3 sources, and a 24-hour cycle. The parallel implementation utilizes tools such as multiprocessing, Dask, and optionally CUDA for GPU acceleration to speed up fitness evaluation, selection, crossover, and mutation operations, while the serial version runs sequentially for baseline comparison. The objective is to evaluate the impact of parallelization on training time, accuracy, and latency. The code outputs execution time comparisons, accuracy metrics, and visualizations, demonstrating that parallel GA significantly reduces training time while maintaining or improving accuracy. The project is implemented in Python, and all necessary files, including the serial and parallel implementations, dataset, and result plots, are provided for reproducibility.
